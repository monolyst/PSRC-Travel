{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove first line from .csv, only needed once!\n",
    "\n",
    "def removeFirstLine():\n",
    "    data_dir = '../data/'\n",
    "\n",
    "    with open(data_dir + '2017-pr2-1-household.csv', 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(data_dir + '2017-pr2-1-household.csv', 'w') as fout:\n",
    "        fout.writelines(data[1:])\n",
    "    \n",
    "    with open(data_dir + '2017-pr2-5-trip.csv', 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(data_dir + '2017-pr2-5-trip.csv', 'w') as fout:\n",
    "        fout.writelines(data[1:])\n",
    "              \n",
    "    with open(data_dir + '2017-pr2-2-person.csv', 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(data_dir + '2017-pr2-2-person.csv', 'w') as fout:\n",
    "        fout.writelines(data[1:])\n",
    "              \n",
    "#removeFirstLine()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    recid      hhid    personid  pernum         tripid  tripnum  tottrip1  \\\n",
      "0  D00001  17100005  1710000501       1  1710000501001        1         5   \n",
      "1  D00002  17100005  1710000501       1  1710000501002        2         5   \n",
      "2  D00003  17100005  1710000501       1  1710000501003        3         5   \n",
      "3  D00004  17100005  1710000501       1  1710000501004        4         5   \n",
      "4  D00005  17100005  1710000501       1  1710000501005        5         5   \n",
      "\n",
      "   tottrip2  daynum  hhgroup         ...          o_rgcname o_taz2010  \\\n",
      "0         5       1        2         ...                NaN    1709.0   \n",
      "1         5       1        2         ...                NaN    1932.0   \n",
      "2         5       1        2         ...                NaN    1929.0   \n",
      "3         5       1        2         ...                NaN    1709.0   \n",
      "4         5       1        2         ...                NaN    1569.0   \n",
      "\n",
      "        d_tract          d_bg  d_puma10 d_rgcname  d_taz2010 nwkdays  \\\n",
      "0  5.303303e+10  5.303303e+11   11607.0       NaN     1932.0       1   \n",
      "1  5.303303e+10  5.303303e+11   11607.0       NaN     1929.0       1   \n",
      "2  5.303303e+10  5.303303e+11   11607.0       NaN     1709.0       1   \n",
      "3  5.303302e+10  5.303302e+11   11608.0       NaN     1569.0       1   \n",
      "4  5.303303e+10  5.303303e+11   11607.0       NaN     1709.0       1   \n",
      "\n",
      "  hh_day_wt_revised  trip_weight_revised  \n",
      "0         24.441709            28.107965  \n",
      "1         24.441709            28.107965  \n",
      "2         24.441709            28.107965  \n",
      "3         24.441709            28.107965  \n",
      "4         24.441709            28.107965  \n",
      "\n",
      "[5 rows x 113 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xx/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (17,18,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,68,69,80,91,92,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load the data sets\n",
    "# Data have been downloaded at https://www.psrc.org/household-travel-survey-program and converted to .csv\n",
    "data_dir = '../data/'\n",
    "\n",
    "df_Household = pd.read_csv(data_dir + '2017-pr2-1-household.csv')\n",
    "df_Trip = pd.read_csv(data_dir + '2017-pr2-5-trip.csv')\n",
    "df_Person = pd.read_csv(data_dir + '2017-pr2-2-person.csv')\n",
    "\n",
    "df_Blockgroup_UrbanVillage = pd.read_csv(data_dir + 'Blockgroup_UrbanVillage.csv')\n",
    "\n",
    "print (df_Trip.head())\n",
    "#print (df_Blockgroup_UrbanVillage.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Persons (Race demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        personid  race_afam  race_aiak  race_asian  race_hapi  race_hisp  \\\n",
      "0     1710000501        0.0        0.0         0.0        0.0        0.0   \n",
      "1     1710000502        0.0        0.0         0.0        0.0        0.0   \n",
      "2     1710002401        0.0        0.0         0.0        0.0        0.0   \n",
      "3     1710002402        0.0        0.0         0.0        0.0        0.0   \n",
      "5     1710005201        0.0        0.0         0.0        0.0        0.0   \n",
      "6     1710005901        0.0        0.0         0.0        0.0        0.0   \n",
      "7     1710006001        0.0        0.0         0.0        0.0        0.0   \n",
      "8     1710010201        0.0        0.0         1.0        0.0        0.0   \n",
      "9     1710010801        0.0        0.0         0.0        0.0        0.0   \n",
      "10    1710010802        0.0        0.0         0.0        0.0        0.0   \n",
      "11    1710011101        0.0        0.0         0.0        0.0        0.0   \n",
      "12    1710011102        0.0        0.0         1.0        0.0        0.0   \n",
      "15    1710013701        0.0        0.0         0.0        0.0        0.0   \n",
      "16    1710014901        0.0        0.0         1.0        0.0        0.0   \n",
      "17    1710014902        0.0        0.0         1.0        0.0        0.0   \n",
      "20    1710017901        0.0        0.0         0.0        0.0        0.0   \n",
      "21    1710017902        0.0        0.0         0.0        0.0        0.0   \n",
      "23    1710020301        0.0        0.0         1.0        0.0        0.0   \n",
      "24    1710020302        0.0        0.0         1.0        0.0        0.0   \n",
      "27    1710020801        0.0        0.0         0.0        0.0        0.0   \n",
      "28    1710020802        0.0        0.0         0.0        0.0        1.0   \n",
      "30    1710022101        0.0        0.0         1.0        0.0        0.0   \n",
      "31    1710023101        0.0        0.0         0.0        0.0        0.0   \n",
      "32    1710023102        0.0        0.0         0.0        0.0        0.0   \n",
      "33    1710023301        0.0        0.0         0.0        0.0        0.0   \n",
      "34    1710023302        0.0        0.0         0.0        0.0        0.0   \n",
      "35    1710023801        0.0        0.0         0.0        0.0        0.0   \n",
      "36    1710023802        0.0        0.0         0.0        0.0        0.0   \n",
      "37    1710024801        0.0        0.0         0.0        0.0        0.0   \n",
      "38    1710025501        0.0        0.0         0.0        0.0        0.0   \n",
      "...          ...        ...        ...         ...        ...        ...   \n",
      "6217  1715374901        0.0        0.0         0.0        0.0        0.0   \n",
      "6218  1715374902        0.0        0.0         0.0        0.0        0.0   \n",
      "6221  1715375101        0.0        0.0         0.0        0.0        0.0   \n",
      "6222  1715378801        0.0        0.0         0.0        0.0        0.0   \n",
      "6223  1715382901        0.0        0.0         0.0        0.0        0.0   \n",
      "6224  1715382902        0.0        0.0         0.0        0.0        0.0   \n",
      "6225  1715383201        0.0        0.0         0.0        0.0        0.0   \n",
      "6226  1715383401        0.0        0.0         0.0        0.0        0.0   \n",
      "6227  1715383402        0.0        0.0         0.0        0.0        0.0   \n",
      "6230  1715385201        0.0        0.0         0.0        0.0        0.0   \n",
      "6231  1715386001        0.0        0.0         1.0        0.0        0.0   \n",
      "6232  1715386501        0.0        0.0         0.0        0.0        0.0   \n",
      "6234  1715391301        0.0        0.0         0.0        0.0        0.0   \n",
      "6235  1715393201        0.0        0.0         0.0        0.0        0.0   \n",
      "6236  1715395901        0.0        0.0         0.0        0.0        0.0   \n",
      "6237  1715395902        0.0        0.0         0.0        0.0        0.0   \n",
      "6238  1715397801        0.0        0.0         0.0        0.0        0.0   \n",
      "6239  1715397802        0.0        0.0         0.0        0.0        0.0   \n",
      "6240  1715397803        0.0        0.0         0.0        0.0        0.0   \n",
      "6242  1715402001        0.0        0.0         0.0        0.0        0.0   \n",
      "6243  1715402002        0.0        0.0         1.0        0.0        0.0   \n",
      "6244  1715410101        0.0        0.0         0.0        0.0        0.0   \n",
      "6245  1715410102        0.0        0.0         0.0        0.0        0.0   \n",
      "6246  1715410801        0.0        0.0         1.0        0.0        0.0   \n",
      "6247  1715412901        0.0        0.0         0.0        0.0        0.0   \n",
      "6248  1715412902        0.0        0.0         0.0        0.0        0.0   \n",
      "6249  1715415201        0.0        0.0         1.0        0.0        0.0   \n",
      "6250  1715415202        0.0        0.0         1.0        0.0        0.0   \n",
      "6252  1715419901        0.0        0.0         1.0        0.0        0.0   \n",
      "6253  1715419902        0.0        0.0         0.0        0.0        0.0   \n",
      "\n",
      "      race_white  race_other  gender  gender_male  gender_female  \\\n",
      "0            1.0         0.0       2            0              1   \n",
      "1            1.0         0.0       1            1              0   \n",
      "2            1.0         0.0       3            0              0   \n",
      "3            1.0         0.0       2            0              1   \n",
      "5            1.0         0.0       2            0              1   \n",
      "6            0.0         1.0       1            1              0   \n",
      "7            1.0         0.0       1            1              0   \n",
      "8            1.0         0.0       1            1              0   \n",
      "9            0.0         0.0       2            0              1   \n",
      "10           0.0         0.0       1            1              0   \n",
      "11           1.0         0.0       2            0              1   \n",
      "12           1.0         0.0       1            1              0   \n",
      "15           1.0         0.0       2            0              1   \n",
      "16           0.0         0.0       1            1              0   \n",
      "17           0.0         0.0       2            0              1   \n",
      "20           1.0         0.0       2            0              1   \n",
      "21           1.0         0.0       1            1              0   \n",
      "23           0.0         0.0       2            0              1   \n",
      "24           0.0         0.0       1            1              0   \n",
      "27           1.0         0.0       2            0              1   \n",
      "28           0.0         1.0       1            1              0   \n",
      "30           1.0         1.0       1            1              0   \n",
      "31           1.0         0.0       1            1              0   \n",
      "32           1.0         0.0       2            0              1   \n",
      "33           0.0         0.0       1            1              0   \n",
      "34           0.0         0.0       2            0              1   \n",
      "35           1.0         0.0       1            1              0   \n",
      "36           1.0         0.0       2            0              1   \n",
      "37           1.0         0.0       1            1              0   \n",
      "38           1.0         0.0       2            0              1   \n",
      "...          ...         ...     ...          ...            ...   \n",
      "6217         1.0         0.0       1            1              0   \n",
      "6218         1.0         0.0       2            0              1   \n",
      "6221         1.0         0.0       2            0              1   \n",
      "6222         1.0         0.0       1            1              0   \n",
      "6223         1.0         0.0       1            1              0   \n",
      "6224         1.0         0.0       1            1              0   \n",
      "6225         0.0         0.0       1            1              0   \n",
      "6226         0.0         0.0       1            1              0   \n",
      "6227         0.0         0.0       2            0              1   \n",
      "6230         1.0         0.0       1            1              0   \n",
      "6231         1.0         0.0       3            0              0   \n",
      "6232         1.0         0.0       1            1              0   \n",
      "6234         1.0         0.0       1            1              0   \n",
      "6235         1.0         0.0       2            0              1   \n",
      "6236         1.0         0.0       1            1              0   \n",
      "6237         1.0         0.0       2            0              1   \n",
      "6238         1.0         0.0       2            0              1   \n",
      "6239         1.0         0.0       1            1              0   \n",
      "6240         1.0         0.0       1            1              0   \n",
      "6242         0.0         0.0       3            0              0   \n",
      "6243         0.0         0.0       3            0              0   \n",
      "6244         0.0         0.0       1            1              0   \n",
      "6245         0.0         0.0       2            0              1   \n",
      "6246         0.0         0.0       1            1              0   \n",
      "6247         1.0         0.0       1            1              0   \n",
      "6248         1.0         0.0       2            0              1   \n",
      "6249         0.0         0.0       1            1              0   \n",
      "6250         0.0         0.0       2            0              1   \n",
      "6252         0.0         0.0       2            0              1   \n",
      "6253         1.0         0.0       1            1              0   \n",
      "\n",
      "      gender_another  gender_noanswer  \n",
      "0                  0                0  \n",
      "1                  0                0  \n",
      "2                  1                0  \n",
      "3                  0                0  \n",
      "5                  0                0  \n",
      "6                  0                0  \n",
      "7                  0                0  \n",
      "8                  0                0  \n",
      "9                  0                0  \n",
      "10                 0                0  \n",
      "11                 0                0  \n",
      "12                 0                0  \n",
      "15                 0                0  \n",
      "16                 0                0  \n",
      "17                 0                0  \n",
      "20                 0                0  \n",
      "21                 0                0  \n",
      "23                 0                0  \n",
      "24                 0                0  \n",
      "27                 0                0  \n",
      "28                 0                0  \n",
      "30                 0                0  \n",
      "31                 0                0  \n",
      "32                 0                0  \n",
      "33                 0                0  \n",
      "34                 0                0  \n",
      "35                 0                0  \n",
      "36                 0                0  \n",
      "37                 0                0  \n",
      "38                 0                0  \n",
      "...              ...              ...  \n",
      "6217               0                0  \n",
      "6218               0                0  \n",
      "6221               0                0  \n",
      "6222               0                0  \n",
      "6223               0                0  \n",
      "6224               0                0  \n",
      "6225               0                0  \n",
      "6226               0                0  \n",
      "6227               0                0  \n",
      "6230               0                0  \n",
      "6231               1                0  \n",
      "6232               0                0  \n",
      "6234               0                0  \n",
      "6235               0                0  \n",
      "6236               0                0  \n",
      "6237               0                0  \n",
      "6238               0                0  \n",
      "6239               0                0  \n",
      "6240               0                0  \n",
      "6242               1                0  \n",
      "6243               1                0  \n",
      "6244               0                0  \n",
      "6245               0                0  \n",
      "6246               0                0  \n",
      "6247               0                0  \n",
      "6248               0                0  \n",
      "6249               0                0  \n",
      "6250               0                0  \n",
      "6252               0                0  \n",
      "6253               0                0  \n",
      "\n",
      "[5401 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Load race information\n",
    "# We are aggregating by household so that we can merge the information with the trip df\n",
    "#print (list(df_Person.columns.values))\n",
    "\n",
    "df_persons = df_Person[['personid','race_afam','race_aiak','race_asian','race_hapi','race_hisp','race_white','race_other','gender']]\n",
    "df_persons.dropna(axis = 0, inplace=True)\n",
    "\n",
    "# assign race variables, calculate\n",
    "#df_race = df_persons.groupby(['hhid'], as_index=False).agg({'race_afam':sum,'race_aiak':sum,\n",
    "#                                                        'race_asian':sum,'race_hapi':sum,\n",
    "#                                                            'race_white':sum,'race_other':sum,\n",
    "#                                                           'race_hisp':sum})\n",
    "\n",
    "#df_race['race_total'] = df_race['race_afam'] + df_race['race_asian'] + df_race['race_hisp'] + df_race['race_white'] + df_race['race_other']\n",
    "#df_race['pct_white'] = df_race['race_white'] / df_race['race_total']\n",
    "\n",
    "# Assign gender variables\n",
    "\n",
    "df_persons['gender_male'] = np.where(df_persons['gender']==1, 1, 0)\n",
    "df_persons['gender_female'] = np.where(df_persons['gender']==2, 1, 0)\n",
    "df_persons['gender_another'] = np.where(df_persons['gender']==3, 1, 0)\n",
    "df_persons['gender_noanswer'] = np.where(df_persons['gender']==4, 1, 0)\n",
    "\n",
    "\n",
    "#df_gender = df_persons.groupby(['hhid'], as_index=False).agg({'gender_male':sum, 'gender_female':sum, \n",
    "#                                                             'gender_another':sum, 'gender_noanswer':sum, })\n",
    "#df_gender['pct_female'] = df_persons['gender_female'] / (df_persons['gender_female'] + df_persons['gender_female'])\n",
    "\n",
    "\n",
    "print (df_persons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_race' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-84de418fcaa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mdf_households\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tenure'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_households\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'res_dur'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"More than 20 years\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_households\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tenure'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdf_households\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_households\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hhid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mdf_households\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_households\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hhid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_race' is not defined"
     ]
    }
   ],
   "source": [
    "# load household data\n",
    "# select columns we want to include in our analysis\n",
    "\n",
    "df_households = df_Household[['final_home_bg','hhid','hhsize','vehicle_count','numchildren',\n",
    "                              'hhincome_broad','car_share','rent_own','res_dur','offpark','hh_wt_revised']]\n",
    "\n",
    "df_households['final_home_bg'] = df_households['final_home_bg'].astype(float).astype(int).astype(str)\n",
    "# merge with seattle block group data\n",
    "df_seattle = df_Blockgroup_UrbanVillage[['BLOCKGROUP','URBAN_VILLAGE_NAME','URBAN_VILLAGE_TYPE']]\n",
    "df_seattle['final_home_bg'] = df_seattle['BLOCKGROUP'].astype(str)\n",
    "\n",
    "df_households = pd.merge(left=df_households, right=df_seattle, how='left', on='final_home_bg')\n",
    "df_households.drop(['BLOCKGROUP'], axis = 1, inplace=True)\n",
    "df_households['URBAN_VILLAGE_NAME'] = df_households['URBAN_VILLAGE_NAME'].fillna(\"Outside Seattle\")\n",
    "df_households['URBAN_VILLAGE_TYPE'] = df_households['URBAN_VILLAGE_TYPE'].fillna(\"Outside Seattle\")\n",
    "\n",
    "df_households = df_households.rename(columns={'final_lat':'hh_lat', 'final_lng':'hh_lng'})\n",
    "df_households = df_households.rename(columns={'URBAN_VILLAGE_NAME':'hh_uv', 'URBAN_VILLAGE_TYPE':'hh_uv_type'})\n",
    "\n",
    "# Assign income variables\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==1, \"Under $25,000\", \"\")\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==2, \"$25,000-$49,999\", df_households['income'])\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==3, \"$50,000-$74,999\", df_households['income'])\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==4, \"$75,000-$99,999\", df_households['income'])\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==5, \"$100,000 or more\", df_households['income'])\n",
    "df_households['income'] = np.where(df_households['hhincome_broad']==6, \"Prefer not to answer\", df_households['income'])\n",
    "\n",
    "# Assign home ownership\n",
    "df_households['homeownership'] = np.where(df_households['rent_own']==1, \"Own\", \"Other\")\n",
    "df_households['homeownership'] = np.where(df_households['rent_own']==2, \"Rent\", df_households['homeownership'])\n",
    "\n",
    "# Assign residency tenure\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==1, \"Less than a year\", \"\")\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==2, \"Between 1 and 2 years\", df_households['tenure'])\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==3, \"Between 2 and 3 years\", df_households['tenure'])\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==4, \"Between 3 and 5 years\", df_households['tenure'])\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==5, \"Between 5 and 10 years\", df_households['tenure'])\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==6, \"Between 10 and 20 years\", df_households['tenure'])\n",
    "df_households['tenure'] = np.where(df_households['res_dur']==7, \"More than 20 years\", df_households['tenure'])\n",
    "\n",
    "df_households = pd.merge(left=df_households, right=df_race, how='left', on='hhid')\n",
    "df_households = pd.merge(left=df_households, right=df_gender, how='left', on='hhid')\n",
    "\n",
    "print (df_households.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xx/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tripid      hhid depart_time_hhmm arrival_time_hhmm          o_bg  \\\n",
      "0  1710000501001  17100005          9:55 AM          10:05 AM  530330323234   \n",
      "1  1710000501002  17100005         10:10 AM          10:15 AM  530330323132   \n",
      "2  1710000501003  17100005         10:50 AM          11:00 AM  530330323133   \n",
      "3  1710000501004  17100005         11:35 AM          12:00 PM  530330323234   \n",
      "4  1710000501005  17100005          3:10 PM           3:30 PM  530330232022   \n",
      "\n",
      "           d_bg    personid  google_duration  trip_path_distance  daynum  \\\n",
      "0  530330323132  1710000501              7.0                2.30       1   \n",
      "1  530330323133  1710000501              4.0                1.12       1   \n",
      "2  530330323234  1710000501              7.0                3.26       1   \n",
      "3  530330232022  1710000501             18.0                8.13       1   \n",
      "4  530330323234  1710000501             16.0                8.04       1   \n",
      "\n",
      "       ...               uv_dest      uvType_dest  \\\n",
      "0      ...       Outside Seattle  Outside Seattle   \n",
      "1      ...       Outside Seattle  Outside Seattle   \n",
      "2      ...       Outside Seattle  Outside Seattle   \n",
      "3      ...       Outside Seattle  Outside Seattle   \n",
      "4      ...       Outside Seattle  Outside Seattle   \n",
      "\n",
      "                           uv_od_pair                    bg_od_pair  \\\n",
      "0  Outside Seattle to Outside Seattle  530330323234 to 530330323132   \n",
      "1  Outside Seattle to Outside Seattle  530330323132 to 530330323133   \n",
      "2  Outside Seattle to Outside Seattle  530330323133 to 530330323234   \n",
      "3  Outside Seattle to Outside Seattle  530330323234 to 530330232022   \n",
      "4  Outside Seattle to Outside Seattle  530330232022 to 530330323234   \n",
      "\n",
      "             mode  drive_alone  purpose depart_time depart_day depart_period  \n",
      "0  Drive w Others            0    Other         9.0          2    Weekday AM  \n",
      "1  Drive w Others            0    Other        10.0          2   Weekday Mid  \n",
      "2  Drive w Others            0  Go Home        10.0          2   Weekday Mid  \n",
      "3     Drive Alone            1    Other        11.0          2   Weekday Mid  \n",
      "4     Drive Alone            1  Go Home        15.0          2   Weekday Mid  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#print (list(df_Trip.columns.values))\n",
    "\n",
    "df_trips = df_Trip[['tripid','hhid', 'depart_time_hhmm','arrival_time_hhmm',\n",
    "                    'o_bg','d_bg','personid','google_duration','trip_path_distance',\n",
    "                    'daynum','origin_purpose','dest_purpose',\n",
    "                    'mode_1','travelers_total','traveldate','trip_weight_revised']]\n",
    "\n",
    "# drop null blockgroups\n",
    "df_trips = df_trips.dropna(subset=['o_bg', 'd_bg'])\n",
    "\n",
    "df_trips['d_bg'] = df_trips['d_bg'].astype(int).astype(str)\n",
    "df_trips['o_bg'] = df_trips['o_bg'].astype(int).astype(str)\n",
    "\n",
    "# merge with seattle block group data\n",
    "df_seattle = df_Blockgroup_UrbanVillage[['BLOCKGROUP','URBAN_VILLAGE_NAME','URBAN_VILLAGE_TYPE']]\n",
    "df_seattle['BLOCKGROUP'] = df_seattle['BLOCKGROUP'].astype(str)\n",
    "                              \n",
    "df_trips = pd.merge(left=df_trips, right=df_seattle, how='left', left_on='o_bg', right_on='BLOCKGROUP')\n",
    "df_trips = df_trips.rename(columns={'URBAN_VILLAGE_NAME':'uv_origin', 'URBAN_VILLAGE_TYPE':'uvType_origin'})\n",
    "df_trips.drop(['BLOCKGROUP'], axis = 1, inplace=True)\n",
    "\n",
    "df_trips['uv_origin'] = df_trips['uv_origin'].fillna(\"Outside Seattle\")\n",
    "df_trips['uvType_origin'] = df_trips['uvType_origin'].fillna(\"Outside Seattle\")\n",
    "\n",
    "df_trips = pd.merge(left=df_trips, right=df_seattle, how='left', left_on='d_bg', right_on='BLOCKGROUP')\n",
    "df_trips = df_trips.rename(columns={'URBAN_VILLAGE_NAME':'uv_dest', 'URBAN_VILLAGE_TYPE':'uvType_dest'})\n",
    "df_trips.drop(['BLOCKGROUP'], axis = 1, inplace=True)\n",
    "\n",
    "df_trips['uv_dest'] = df_trips['uv_dest'].fillna(\"Outside Seattle\")\n",
    "df_trips['uvType_dest'] = df_trips['uvType_dest'].fillna(\"Outside Seattle\")\n",
    "\n",
    "# Drop missing variables, clean up column\n",
    "df_trips['mode_1'] = df_trips['mode_1'].fillna(0)\n",
    "df_trips['mode_1'] = df_trips['mode_1'].astype(str).replace(' ', '0')\n",
    "df_trips['mode_1'] = df_trips['mode_1'].astype(str).astype(int)\n",
    "df_trips['travelers_total'] = df_trips['travelers_total'].astype(str).replace(' ', '0')\n",
    "df_trips['travelers_total'] = df_trips['travelers_total'].astype(str).astype(int)\n",
    "\n",
    "# drop rows where the duration or distance is null or an empty space\n",
    "df_trips = df_trips[df_trips['google_duration'].notnull()]\n",
    "df_trips = df_trips[df_trips['trip_path_distance'].notnull()]\n",
    "df_trips = df_trips[df_trips['google_duration'] != \" \"]\n",
    "df_trips = df_trips[df_trips['trip_path_distance'] != \" \"]\n",
    "df_trips['google_duration'] = df_trips['google_duration'].astype(float)\n",
    "df_trips['trip_path_distance'] = df_trips['trip_path_distance'].astype(float)\n",
    "df_trips = df_trips[df_trips['trip_path_distance'].notnull()]\n",
    "\n",
    "# Create OD Pairs for urban villages and block groups\n",
    "df_trips['uv_od_pair'] = df_trips['uv_origin'] + \" to \" + df_trips['uv_dest']\n",
    "df_trips['bg_od_pair'] = df_trips['o_bg'].astype(str) + \" to \" + df_trips['d_bg'].astype(str)\n",
    "\n",
    "# Assign mode variables\n",
    "df_trips['mode'] = np.where(df_trips['mode_1']==1, \"Walk\", \"Other\")\n",
    "df_trips['mode'] = np.where(df_trips['mode_1']==2, \"Bike\", df_trips['mode'])\n",
    "\n",
    "df_trips['mode'] = np.where((df_trips['mode_1']>=3) & (df_trips['mode_1']<=17)  & (df_trips['travelers_total']==1), \"Drive Alone\", df_trips['mode'])\n",
    "df_trips['mode'] = np.where(((df_trips['mode_1']==21) | (df_trips['mode_1']==22) |\n",
    "                                 (df_trips['mode_1']==33) | (df_trips['mode_1']==34) | (df_trips['mode_1']==18))\n",
    "                                 & (df_trips['travelers_total']==1), \"Drive Alone\", df_trips['mode'])\n",
    "\n",
    "df_trips['mode'] = np.where((df_trips['mode_1']>=3) & (df_trips['mode_1']<=17)  & (df_trips['travelers_total']!=1), \"Drive w Others\", df_trips['mode'])\n",
    "df_trips['mode'] = np.where(((df_trips['mode_1']==21) | (df_trips['mode_1']==22) |\n",
    "                                 (df_trips['mode_1']==33) | (df_trips['mode_1']==34) | (df_trips['mode_1']==18))\n",
    "                                 & (df_trips['travelers_total']>1), \"Drive w Others\", df_trips['mode'])\n",
    "\n",
    "df_trips['mode'] = np.where((df_trips['mode_1']==23) | (df_trips['mode_1']==41) | (df_trips['travelers_total']==42), \"Transit\", df_trips['mode'])\n",
    "df_trips['mode'] = np.where((df_trips['mode_1']==32) | (df_trips['travelers_total']==52), \"Transit\", df_trips['mode'])\n",
    "\n",
    "df_trips['drive_alone'] = np.where(df_trips['mode']==\"Drive Alone\", 1, 0)\n",
    "\n",
    "\n",
    "# Assign purpose variables\n",
    "df_trips['purpose'] = np.where(df_trips['dest_purpose']==1, \"Go Home\", \"Other\")\n",
    "df_trips['purpose'] = np.where(df_trips['dest_purpose']==6, \"School\", df_trips['purpose'])\n",
    "df_trips['purpose'] = np.where((df_trips['dest_purpose']==10) | (df_trips['dest_purpose']==11), \"Work\", df_trips['purpose'])\n",
    "\n",
    "# Assign time period variables\n",
    "df_trips['depart_time'] = pd.to_datetime(df_trips['depart_time_hhmm'], errors='coerce')\n",
    "df_trips['depart_day'] = pd.to_datetime(df_trips['traveldate'], errors='coerce')\n",
    "\n",
    "df_trips['depart_day'] = df_trips['depart_day'].dt.dayofweek\n",
    "df_trips['depart_time'] = df_trips['depart_time'].dt.hour\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=0) & (df_trips['depart_day']<=4) & \n",
    "                                     (df_trips['depart_time']>=7) & (df_trips['depart_time']<=9), \"Weekday AM\", \"\")\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=0) & (df_trips['depart_day']<=4) & \n",
    "                                     (df_trips['depart_time']>=10) & (df_trips['depart_time']<=15), \"Weekday Mid\", df_trips['depart_period'])\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=0) & (df_trips['depart_day']<=4) & \n",
    "                                     (df_trips['depart_time']>=16) & (df_trips['depart_time']<=19), \"Weekday PM\", df_trips['depart_period'])\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=0) & (df_trips['depart_day']<=4) & \n",
    "                                     (df_trips['depart_time']<7), \"Other\", df_trips['depart_period'])\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=0) & (df_trips['depart_day']<=4) & \n",
    "                                     (df_trips['depart_time']>19), \"Late Night\", df_trips['depart_period'])\n",
    "\n",
    "df_trips['depart_period'] = np.where((df_trips['depart_day']>=5) & (df_trips['depart_day']<=6), \"Late Night\", df_trips['depart_period'])\n",
    "\n",
    "#dts = dfBad[cols].apply(lambda x: pd.to_datetime(x, errors='coerce', format='%m/%d/%Y'))\n",
    "#pd.to_datetime(df_trips['depart_time_timestamp'])\n",
    "\n",
    "#df_trips['depart_time_timestamp'] = datetime.strptime(df_trips['depart_time_timestamp'], '%b %d %Y %I:%M%p')\n",
    "#to_datetime\n",
    "\n",
    "#print (df_trips.dtypes)\n",
    "print (df_trips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin and Destination Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'origin_lat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin_lat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7fad6b47029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#aggregate by urban village origin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m df_UV_Origins = df_trips_Seattle.groupby(['uv_origin'], as_index=False).agg({'google_duration':['mean','std','skew'],'trip_path_distance':['mean'],\n\u001b[0;32m----> 8\u001b[0;31m                                                                             'origin_lat':['mean','std','skew'],'origin_lng':['mean']})\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_UV_Origins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3959\u001b[0m         versionadded=''))\n\u001b[1;32m   3960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3961\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m         \u001b[0m_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3393\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3395\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_agg_1dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg\u001b[0;34m(arg, func)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg_1dim\u001b[0;34m(name, how, subset)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0maggregate\u001b[0m \u001b[0ma\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mcolg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     raise SpecificationError(\"nested dictionary is ambiguous \"\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_gotitem\u001b[0;34m(self, key, ndim, subset)\u001b[0m\n\u001b[1;32m   3986\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3988\u001b[0;31m                 \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3989\u001b[0m             return SeriesGroupBy(subset, selection=key,\n\u001b[1;32m   3990\u001b[0m                                  grouper=self.grouper)\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xx/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin_lat'"
     ]
    }
   ],
   "source": [
    "#filter for only trips starting and ending in Seattle\n",
    "df_trips_Seattle = df_trips[(df_trips['uv_origin'] != 'Outside Seattle') | (df_trips['uv_dest'] != 'Outside Seattle')]\n",
    "\n",
    "#print (df_trips_Seattle)\n",
    "\n",
    "#aggregate by urban village origin\n",
    "df_UV_Origins = df_trips_Seattle.groupby(['uv_origin'], as_index=False).agg({'google_duration':['mean','std','skew'],'trip_path_distance':['mean'],\n",
    "                                                                            'origin_lat':['mean','std','skew'],'origin_lng':['mean']})\n",
    "\n",
    "print (df_UV_Origins.head())\n",
    "\n",
    "#aggregate by urban village destination\n",
    "df_UV_Destinations = df_trips_Seattle.groupby(['uv_dest'], as_index=False).agg({'google_duration':['mean'],'trip_path_distance':['mean'],\n",
    "                                                                                          'dest_lat':['mean'],'dest_lng':['mean']})\n",
    "#print (df_UV_Destinations.head())\n",
    "\n",
    "#aggregate by urban village OD Pair\n",
    "df_UV_ODPair = df_trips_Seattle.groupby(['uv_od_pair'], as_index=False).agg({'google_duration':['mean'],'trip_path_distance':['mean'],\n",
    "                                                                                          'origin_lat':['mean'],'origin_lat':['mean'],\n",
    "                                                                                          'dest_lat':['mean'],'dest_lng':['mean']})\n",
    "#print (df_UV_ODPair.head())\n",
    "\n",
    "##aggregate by blockgroup origin\n",
    "df_BG_Origins = df_trips_Seattle.groupby(['bg_origin'], as_index=False).agg({'google_duration':['mean'],'trip_path_distance':['mean'],\n",
    "                                                                            'origin_lat':['mean'],'origin_lng':['mean']})\n",
    "#print (df_BG_Origins)\n",
    "\n",
    "#aggregate by blockgroup destination\n",
    "df_BG_Destinations = df_trips_Seattle.groupby(['bg_dest'], as_index=False).agg({'google_duration':['mean'],'trip_path_distance':['mean'],\n",
    "                                                                                          'dest_lat':['mean'],'dest_lng':['mean']})\n",
    "#print (df_BG_Destinations.head())\n",
    "\n",
    "#aggregate by urban village OD Pair\n",
    "df_BG_ODPair = df_trips_Seattle.groupby(['bg_od_pair'], as_index=False).agg({'google_duration':['mean'],'trip_path_distance':['mean'],\n",
    "                                                                            'origin_lat':['mean'],'origin_lng':['mean'],\n",
    "                                                                             'dest_lat':['mean'],'dest_lng':['mean']})\n",
    "df_BG_ODPair.columns = df_BG_ODPair.columns.droplevel(level=1)\n",
    "\n",
    "df_BG_ODPair.to_csv(data_dir + 'df_BG_ODPair.csv', mode='w', header=True, index=False)\n",
    "df_BG_Origins.to_csv(data_dir + 'BG_Origins.csv', mode='w', header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged, Normalized Trip Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tripid      hhid depart_time_hhmm arrival_time_hhmm          o_bg  \\\n",
      "0  1710000501001  17100005          9:55 AM          10:05 AM  530330323234   \n",
      "1  1710000501002  17100005         10:10 AM          10:15 AM  530330323132   \n",
      "2  1710000501003  17100005         10:50 AM          11:00 AM  530330323133   \n",
      "3  1710000501004  17100005         11:35 AM          12:00 PM  530330323234   \n",
      "4  1710000501005  17100005          3:10 PM           3:30 PM  530330232022   \n",
      "\n",
      "           d_bg    personid  google_duration  trip_path_distance  daynum  \\\n",
      "0  530330323132  1710000501              7.0                2.30       1   \n",
      "1  530330323133  1710000501              4.0                1.12       1   \n",
      "2  530330323234  1710000501              7.0                3.26       1   \n",
      "3  530330232022  1710000501             18.0                8.13       1   \n",
      "4  530330323234  1710000501             16.0                8.04       1   \n",
      "\n",
      "        ...        race_asian  race_hapi  race_hisp  race_white race_other  \\\n",
      "0       ...               0.0        0.0        0.0         1.0        0.0   \n",
      "1       ...               0.0        0.0        0.0         1.0        0.0   \n",
      "2       ...               0.0        0.0        0.0         1.0        0.0   \n",
      "3       ...               0.0        0.0        0.0         1.0        0.0   \n",
      "4       ...               0.0        0.0        0.0         1.0        0.0   \n",
      "\n",
      "   gender gender_male gender_female gender_another gender_noanswer  \n",
      "0     2.0         0.0           1.0            0.0             0.0  \n",
      "1     2.0         0.0           1.0            0.0             0.0  \n",
      "2     2.0         0.0           1.0            0.0             0.0  \n",
      "3     2.0         0.0           1.0            0.0             0.0  \n",
      "4     2.0         0.0           1.0            0.0             0.0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "df_trip_household= pd.merge(left=df_trips, right=df_households, how='left', left_on='hhid', right_on='hhid')\n",
    "df_trip_household= pd.merge(left=df_trips, right=df_persons, how='left', left_on='personid', right_on='personid')\n",
    "\n",
    "print (df_trip_household.head())\n",
    "\n",
    "df_trip_household.to_csv(data_dir + 'Trip_Household_Merged.csv', mode='w', header=True, index=False)\n",
    "#df_UV_Origins.to_csv(data_dir + 'UV_Origins.csv', mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blockgroup Pairs\n",
    "This section calculates all combinations of blockgroups pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        bg_pair          o_bg          d_bg  lat_dest  \\\n",
      "0     530330001001-530330001005  530330001001  530330001005  47.72293   \n",
      "1     530330001001-530330007001  530330001001  530330007001  47.71744   \n",
      "2     530330001001-530330042003  530330001001  530330042003  47.66471   \n",
      "3     530330001001-530330053023  530330001001  530330053023  47.65576   \n",
      "4     530330001001-530330067001  530330001001  530330067001  47.63238   \n",
      "5     530330001002-530330001003  530330001002  530330001003  47.72281   \n",
      "6     530330001002-530330007001  530330001002  530330007001  47.71744   \n",
      "7     530330001002-530330018001  530330001002  530330018001  47.69420   \n",
      "8     530330001002-530330018002  530330001002  530330018002  47.69222   \n",
      "9     530330001002-530330093002  530330001002  530330093002  47.58946   \n",
      "10    530330001003-530330001002  530330001003  530330001002  47.72932   \n",
      "11    530330001003-530330001003  530330001003  530330001003  47.72281   \n",
      "12    530330001003-530330001005  530330001003  530330001005  47.72293   \n",
      "13    530330001003-530330002002  530330001003  530330002002  47.72179   \n",
      "14    530330001003-530330002004  530330001003  530330002004  47.72866   \n",
      "15    530330001003-530330002005  530330001003  530330002005  47.72274   \n",
      "16    530330001003-530330007001  530330001003  530330007001  47.71744   \n",
      "17    530330001003-530330007002  530330001003  530330007002  47.71478   \n",
      "18    530330001003-530330009001  530330001003  530330009001  47.71280   \n",
      "19    530330001003-530330012005  530330001003  530330012005  47.70760   \n",
      "20    530330001003-530330026003  530330001003  530330026003  47.67762   \n",
      "21    530330001003-530330043021  530330001003  530330043021  47.66493   \n",
      "22    530330001003-530330052005  530330001003  530330052005  47.66260   \n",
      "23    530330001003-530330071002  530330001003  530330071002  47.62173   \n",
      "24    530330001003-530330079002  530330001003  530330079002  47.61392   \n",
      "25    530330001003-530330081002  530330001003  530330081002  47.60683   \n",
      "26    530330001004-530330018003  530330001004  530330018003  47.69541   \n",
      "27    530330001005-530330001002  530330001005  530330001002  47.72932   \n",
      "28    530330001005-530330001003  530330001005  530330001003  47.72281   \n",
      "29    530330001005-530330001005  530330001005  530330001005  47.72293   \n",
      "...                         ...           ...           ...       ...   \n",
      "9845  530330118006-530330118006  530330118006  530330118006  47.52565   \n",
      "9846  530330118006-530330119002  530330118006  530330119002  47.50492   \n",
      "9847  530330119002-530330053022  530330119002  530330053022  47.65133   \n",
      "9848  530330119002-530330118006  530330119002  530330118006  47.52565   \n",
      "9849  530330119002-530330119003  530330119002  530330119003  47.50507   \n",
      "9850  530330119003-530330093003  530330119003  530330093003  47.56956   \n",
      "9851  530330119003-530330119002  530330119003  530330119002  47.50492   \n",
      "9852  530330119005-530330098004  530330119005  530330098004  47.56596   \n",
      "9853  530330119005-530330103004  530330119005  530330103004  47.55695   \n",
      "9854  530330119005-530330104021  530330119005  530330104021  47.55085   \n",
      "9855  530330119005-530330119005  530330119005  530330119005  47.50867   \n",
      "9856  530330120002-530330100013  530330120002  530330100013  47.56472   \n",
      "9857  530330120002-530330114021  530330120002  530330114021  47.52299   \n",
      "9858  530330120002-530330115001  530330120002  530330115001  47.53244   \n",
      "9859  530330120002-530330116005  530330120002  530330116005  47.52365   \n",
      "9860  530330120003-530330066002  530330120003  530330066002  47.63740   \n",
      "9861  530330120003-530330081002  530330120003  530330081002  47.60683   \n",
      "9862  530330120003-530330095002  530330120003  530330095002  47.58679   \n",
      "9863  530330120003-530330106003  530330120003  530330106003  47.54308   \n",
      "9864  530330121001-530330075003  530330121001  530330075003  47.62268   \n",
      "9865  530330121001-530330083001  530330121001  530330083001  47.60982   \n",
      "9866  530330121001-530330099004  530330121001  530330099004  47.57685   \n",
      "9867  530330121002-530330054003  530330121002  530330054003  47.65027   \n",
      "9868  530330121002-530330074014  530330121002  530330074014  47.62200   \n",
      "9869  530330121002-530330097013  530330121002  530330097013  47.57465   \n",
      "9870  530330121002-530330109002  530330121002  530330109002  47.54909   \n",
      "9871  530330121002-530330114021  530330121002  530330114021  47.52299   \n",
      "9872  530330264004-530330058023  530330264004  530330058023  47.63486   \n",
      "9873  530330264005-530330112002  530330264005  530330112002  47.53371   \n",
      "9874  530330264005-530330112003  530330264005  530330112003  47.52457   \n",
      "\n",
      "       lon_dest    BLOCKGROUP URBAN_VILLAGE_NAME         URBAN_VILLAGE_TYPE  \\\n",
      "0    -122.29444  530330001001   Outside Villages           Outside Villages   \n",
      "1    -122.29460  530330001001   Outside Villages           Outside Villages   \n",
      "2    -122.29037  530330001001   Outside Villages           Outside Villages   \n",
      "3    -122.30146  530330001001   Outside Villages           Outside Villages   \n",
      "4    -122.34156  530330001001   Outside Villages           Outside Villages   \n",
      "5    -122.28945  530330001002   Outside Villages           Outside Villages   \n",
      "6    -122.29460  530330001002   Outside Villages           Outside Villages   \n",
      "7    -122.33757  530330001002   Outside Villages           Outside Villages   \n",
      "8    -122.34438  530330001002   Outside Villages           Outside Villages   \n",
      "9    -122.33534  530330001002   Outside Villages           Outside Villages   \n",
      "10   -122.29247  530330001003   Outside Villages           Outside Villages   \n",
      "11   -122.28945  530330001003   Outside Villages           Outside Villages   \n",
      "12   -122.29444  530330001003   Outside Villages           Outside Villages   \n",
      "13   -122.30283  530330001003   Outside Villages           Outside Villages   \n",
      "14   -122.31018  530330001003   Outside Villages           Outside Villages   \n",
      "15   -122.31391  530330001003   Outside Villages           Outside Villages   \n",
      "16   -122.29460  530330001003   Outside Villages           Outside Villages   \n",
      "17   -122.29738  530330001003   Outside Villages           Outside Villages   \n",
      "18   -122.27963  530330001003   Outside Villages           Outside Villages   \n",
      "19   -122.33162  530330001003   Outside Villages           Outside Villages   \n",
      "20   -122.31200  530330001003   Outside Villages           Outside Villages   \n",
      "21   -122.30515  530330001003   Outside Villages           Outside Villages   \n",
      "22   -122.31946  530330001003   Outside Villages           Outside Villages   \n",
      "23   -122.35361  530330001003   Outside Villages           Outside Villages   \n",
      "24   -122.30702  530330001003   Outside Villages           Outside Villages   \n",
      "25   -122.33430  530330001003   Outside Villages           Outside Villages   \n",
      "26   -122.34656  530330001004   Outside Villages           Outside Villages   \n",
      "27   -122.29247  530330001005   Outside Villages           Outside Villages   \n",
      "28   -122.28945  530330001005   Outside Villages           Outside Villages   \n",
      "29   -122.29444  530330001005   Outside Villages           Outside Villages   \n",
      "...         ...           ...                ...                        ...   \n",
      "9845 -122.26783  530330118006      Rainier Beach  Residential Urban Village   \n",
      "9846 -122.24867  530330118006      Rainier Beach  Residential Urban Village   \n",
      "9847 -122.31173  530330119002   Outside Villages           Outside Villages   \n",
      "9848 -122.26783  530330119002   Outside Villages           Outside Villages   \n",
      "9849 -122.25784  530330119002   Outside Villages           Outside Villages   \n",
      "9850 -122.32926  530330119003   Outside Villages           Outside Villages   \n",
      "9851 -122.24867  530330119003   Outside Villages           Outside Villages   \n",
      "9852 -122.38536  530330119005   Outside Villages           Outside Villages   \n",
      "9853 -122.28861  530330119005   Outside Villages           Outside Villages   \n",
      "9854 -122.31166  530330119005   Outside Villages           Outside Villages   \n",
      "9855 -122.26594  530330119005   Outside Villages           Outside Villages   \n",
      "9856 -122.29873  530330120002   Outside Villages           Outside Villages   \n",
      "9857 -122.36405  530330120002   Outside Villages           Outside Villages   \n",
      "9858 -122.37249  530330120002   Outside Villages           Outside Villages   \n",
      "9859 -122.39167  530330120002   Outside Villages           Outside Villages   \n",
      "9860 -122.32593  530330120003   Outside Villages           Outside Villages   \n",
      "9861 -122.33430  530330120003   Outside Villages           Outside Villages   \n",
      "9862 -122.29805  530330120003   Outside Villages           Outside Villages   \n",
      "9863 -122.38558  530330120003   Outside Villages           Outside Villages   \n",
      "9864 -122.31832  530330121001   Outside Villages           Outside Villages   \n",
      "9865 -122.32635  530330121001   Outside Villages           Outside Villages   \n",
      "9866 -122.35977  530330121001   Outside Villages           Outside Villages   \n",
      "9867 -122.34249  530330121002   Outside Villages           Outside Villages   \n",
      "9868 -122.32485  530330121002   Outside Villages           Outside Villages   \n",
      "9869 -122.41426  530330121002   Outside Villages           Outside Villages   \n",
      "9870 -122.32864  530330121002   Outside Villages           Outside Villages   \n",
      "9871 -122.36405  530330121002   Outside Villages           Outside Villages   \n",
      "9872 -122.38204  530330264004   Outside Villages           Outside Villages   \n",
      "9873 -122.32813  530330264005   Outside Villages           Outside Villages   \n",
      "9874 -122.31654  530330264005   Outside Villages           Outside Villages   \n",
      "\n",
      "     NEIGHBORHOOD_DISTRICT_NAME  \\\n",
      "0                         North   \n",
      "1                         North   \n",
      "2                         North   \n",
      "3                         North   \n",
      "4                         North   \n",
      "5                         North   \n",
      "6                         North   \n",
      "7                         North   \n",
      "8                         North   \n",
      "9                         North   \n",
      "10                        North   \n",
      "11                        North   \n",
      "12                        North   \n",
      "13                        North   \n",
      "14                        North   \n",
      "15                        North   \n",
      "16                        North   \n",
      "17                        North   \n",
      "18                        North   \n",
      "19                        North   \n",
      "20                        North   \n",
      "21                        North   \n",
      "22                        North   \n",
      "23                        North   \n",
      "24                        North   \n",
      "25                        North   \n",
      "26                        North   \n",
      "27                        North   \n",
      "28                        North   \n",
      "29                        North   \n",
      "...                         ...   \n",
      "9845                  Southeast   \n",
      "9846                  Southeast   \n",
      "9847                  Southeast   \n",
      "9848                  Southeast   \n",
      "9849                  Southeast   \n",
      "9850                  Southeast   \n",
      "9851                  Southeast   \n",
      "9852                  Southeast   \n",
      "9853                  Southeast   \n",
      "9854                  Southeast   \n",
      "9855                  Southeast   \n",
      "9856                  Southwest   \n",
      "9857                  Southwest   \n",
      "9858                  Southwest   \n",
      "9859                  Southwest   \n",
      "9860                  Southwest   \n",
      "9861                  Southwest   \n",
      "9862                  Southwest   \n",
      "9863                  Southwest   \n",
      "9864                  Southwest   \n",
      "9865                  Southwest   \n",
      "9866                  Southwest   \n",
      "9867                  Southwest   \n",
      "9868                  Southwest   \n",
      "9869                  Southwest   \n",
      "9870                  Southwest   \n",
      "9871                  Southwest   \n",
      "9872           Greater Duwamish   \n",
      "9873           Greater Duwamish   \n",
      "9874           Greater Duwamish   \n",
      "\n",
      "                                 NEIGHBORHOODS_INCLUDED  \\\n",
      "0     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "1     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "2     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "3     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "4     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "5     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "6     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "7     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "8     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "9     Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "10    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "11    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "12    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "13    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "14    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "15    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "16    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "17    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "18    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "19    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "20    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "21    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "22    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "23    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "24    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "25    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "26    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "27    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "28    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "29    Cedar Park, Lake City, Meadowbrook, Matthews B...   \n",
      "...                                                 ...   \n",
      "9845    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9846    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9847    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9848    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9849    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9850    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9851    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9852    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9853    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9854    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9855    Rainier Beach, Rainier View, Lake Ridge, Dunlap   \n",
      "9856       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9857       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9858       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9859       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9860       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9861       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9862       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9863       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9864       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9865       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9866       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9867       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9868       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9869       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9870       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9871       Arbor Heights, Brace Point, Endolyne, Arroyo   \n",
      "9872                                         South Park   \n",
      "9873                                         South Park   \n",
      "9874                                         South Park   \n",
      "\n",
      "                    CRA_NAME  PCT_IN_VILLAGE          AREA  lon_origin  \\\n",
      "0     Cedar Park/Meadowbrook        1.000000  8.967593e+06  -122.28469   \n",
      "1     Cedar Park/Meadowbrook        1.000000  8.967593e+06  -122.28469   \n",
      "2     Cedar Park/Meadowbrook        1.000000  8.967593e+06  -122.28469   \n",
      "3     Cedar Park/Meadowbrook        1.000000  8.967593e+06  -122.28469   \n",
      "4     Cedar Park/Meadowbrook        1.000000  8.967593e+06  -122.28469   \n",
      "5     Cedar Park/Meadowbrook        1.000000  3.104000e+06  -122.29247   \n",
      "6     Cedar Park/Meadowbrook        1.000000  3.104000e+06  -122.29247   \n",
      "7     Cedar Park/Meadowbrook        1.000000  3.104000e+06  -122.29247   \n",
      "8     Cedar Park/Meadowbrook        1.000000  3.104000e+06  -122.29247   \n",
      "9     Cedar Park/Meadowbrook        1.000000  3.104000e+06  -122.29247   \n",
      "10    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "11    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "12    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "13    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "14    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "15    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "16    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "17    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "18    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "19    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "20    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "21    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "22    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "23    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "24    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "25    Cedar Park/Meadowbrook        0.666667  3.990298e+06  -122.28945   \n",
      "26    Cedar Park/Meadowbrook        1.000000  1.360694e+06  -122.29445   \n",
      "27    Cedar Park/Meadowbrook        0.571429  2.481027e+06  -122.29444   \n",
      "28    Cedar Park/Meadowbrook        0.571429  2.481027e+06  -122.29444   \n",
      "29    Cedar Park/Meadowbrook        0.571429  2.481027e+06  -122.29444   \n",
      "...                      ...             ...           ...         ...   \n",
      "9845           Rainier Beach        0.571429  5.821336e+06  -122.26783   \n",
      "9846           Rainier Beach        0.571429  5.821336e+06  -122.26783   \n",
      "9847           Rainier Beach        1.000000  7.327446e+06  -122.24867   \n",
      "9848           Rainier Beach        1.000000  7.327446e+06  -122.24867   \n",
      "9849           Rainier Beach        1.000000  7.327446e+06  -122.24867   \n",
      "9850           Rainier Beach        1.000000  4.818607e+06  -122.25784   \n",
      "9851           Rainier Beach        1.000000  4.818607e+06  -122.25784   \n",
      "9852           Rainier Beach        1.000000  9.208955e+06  -122.26594   \n",
      "9853           Rainier Beach        1.000000  9.208955e+06  -122.26594   \n",
      "9854           Rainier Beach        1.000000  9.208955e+06  -122.26594   \n",
      "9855           Rainier Beach        1.000000  9.208955e+06  -122.26594   \n",
      "9856           Arbor Heights        1.000000  5.475699e+06  -122.38054   \n",
      "9857           Arbor Heights        1.000000  5.475699e+06  -122.38054   \n",
      "9858           Arbor Heights        1.000000  5.475699e+06  -122.38054   \n",
      "9859           Arbor Heights        1.000000  5.475699e+06  -122.38054   \n",
      "9860           Arbor Heights        1.000000  5.087951e+06  -122.38600   \n",
      "9861           Arbor Heights        1.000000  5.087951e+06  -122.38600   \n",
      "9862           Arbor Heights        1.000000  5.087951e+06  -122.38600   \n",
      "9863           Arbor Heights        1.000000  5.087951e+06  -122.38600   \n",
      "9864           Arbor Heights        1.000000  9.113717e+06  -122.38993   \n",
      "9865           Arbor Heights        1.000000  9.113717e+06  -122.38993   \n",
      "9866           Arbor Heights        1.000000  9.113717e+06  -122.38993   \n",
      "9867           Arbor Heights        1.000000  9.182014e+06  -122.37688   \n",
      "9868           Arbor Heights        1.000000  9.182014e+06  -122.37688   \n",
      "9869           Arbor Heights        1.000000  9.182014e+06  -122.37688   \n",
      "9870           Arbor Heights        1.000000  9.182014e+06  -122.37688   \n",
      "9871           Arbor Heights        1.000000  9.182014e+06  -122.37688   \n",
      "9872              South Park        1.000000  1.200200e+07  -122.32227   \n",
      "9873              South Park        1.000000  7.657025e+06  -122.31928   \n",
      "9874              South Park        1.000000  7.657025e+06  -122.31928   \n",
      "\n",
      "      lat_origin  \n",
      "0       47.72683  \n",
      "1       47.72683  \n",
      "2       47.72683  \n",
      "3       47.72683  \n",
      "4       47.72683  \n",
      "5       47.72932  \n",
      "6       47.72932  \n",
      "7       47.72932  \n",
      "8       47.72932  \n",
      "9       47.72932  \n",
      "10      47.72281  \n",
      "11      47.72281  \n",
      "12      47.72281  \n",
      "13      47.72281  \n",
      "14      47.72281  \n",
      "15      47.72281  \n",
      "16      47.72281  \n",
      "17      47.72281  \n",
      "18      47.72281  \n",
      "19      47.72281  \n",
      "20      47.72281  \n",
      "21      47.72281  \n",
      "22      47.72281  \n",
      "23      47.72281  \n",
      "24      47.72281  \n",
      "25      47.72281  \n",
      "26      47.73194  \n",
      "27      47.72293  \n",
      "28      47.72293  \n",
      "29      47.72293  \n",
      "...          ...  \n",
      "9845    47.52565  \n",
      "9846    47.52565  \n",
      "9847    47.50492  \n",
      "9848    47.50492  \n",
      "9849    47.50492  \n",
      "9850    47.50507  \n",
      "9851    47.50507  \n",
      "9852    47.50867  \n",
      "9853    47.50867  \n",
      "9854    47.50867  \n",
      "9855    47.50867  \n",
      "9856    47.51008  \n",
      "9857    47.51008  \n",
      "9858    47.51008  \n",
      "9859    47.51008  \n",
      "9860    47.51481  \n",
      "9861    47.51481  \n",
      "9862    47.51481  \n",
      "9863    47.51481  \n",
      "9864    47.51039  \n",
      "9865    47.51039  \n",
      "9866    47.51039  \n",
      "9867    47.50355  \n",
      "9868    47.50355  \n",
      "9869    47.50355  \n",
      "9870    47.50355  \n",
      "9871    47.50355  \n",
      "9872    47.50997  \n",
      "9873    47.51616  \n",
      "9874    47.51616  \n",
      "\n",
      "[9875 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_Blockgroups = pd.read_csv(data_dir + 'SeattleCensusBlocksandNeighborhoodCorrelationFile.csv') \n",
    "df_Blockgroups['BLOCKGROUP'] = df_Blockgroups['BLOCKGROUP'].astype(str)\n",
    "\n",
    "df_Merged= pd.merge(left=df_trips, right=df_Blockgroups, how='inner', left_on='d_bg', right_on='BLOCKGROUP')\n",
    "#print (list(df_Merged.columns.values))\n",
    "\n",
    "df_Merged['bg_pair'] = df_Merged['o_bg'].astype(str) + \"-\" + df_Merged['d_bg'].astype(str)\n",
    "\n",
    "df_Merged_agg = df_Merged.groupby(['bg_pair'], as_index=False).agg({'o_bg':['max'],'d_bg':['max'],\n",
    "                                                                   'CT_LAT':['max'],'CT_LON':['max']})\n",
    "df_Merged_agg.columns = df_Merged_agg.columns.droplevel(level=1)\n",
    "df_Merged_agg = df_Merged_agg.rename(index=str, columns={\"CT_LAT\": \"lat_dest\", \"CT_LON\": \"lon_dest\"})\n",
    "\n",
    "df_Merged_agg= pd.merge(left=df_Merged_agg, right=df_Blockgroups, how='inner', left_on='o_bg', right_on='BLOCKGROUP')\n",
    "df_Merged_agg = df_Merged_agg.rename(index=str, columns={\"CT_LAT\": \"lat_origin\", \"CT_LON\": \"lon_origin\"})\n",
    "\n",
    "df_Merged_agg.to_csv(data_dir + 'blockgroup_pairs.csv', mode='w', header=True, index=False)\n",
    "\n",
    "\n",
    "print (df_Merged_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
